{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "AI Ranger Team Demo Development\n",
        "# Deep Learning for Medical Image Analysis leveraging the AML Platform\n",
        "### Pneunomia detection using Remote Experiment Runs and Azure ML Pipeines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"images/medicalimage.jpg\" width=1000 />\n",
        "\n",
        "### In this notebook\n",
        "In this notebook, three different approaches are demonstrated to train a Pneumonia detection model using the unique capabilities of Azure ML. We will start by training a baseline model, which is trained on a remote cluster with GPU machines. The second part will show an approach for training hyperparameters. The third and last part of the notebook, will transform the Remote Experiment Runs in a Azure ML Pipeline, that can be used to train a model repeatably when new data is available. The Pipeline will also include a step for deployment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pneumonia Detection Use Case\n",
        "A relatively small public dataset of medical images for detecting viral or bacterial pneumonia has been chosen to keep the scenario straightforward and reproducible with limited computing resources. The dataset contains 5,218 x-ray images with two classes of diagnostic outcomes: 3,876 cases with (viral or bacterial) pneumonia and 1,342 cases without findings (\"Normal\").\n",
        "The dataset is split into training, validation and test sets. Since some images represent radiographs from the same patient, it has been ensured that there is no overlap of patients between the training, validation and test sets.\n",
        "\n",
        "<img src=\"images/pneumonia.png\" width=1000 />\n",
        "You can find the dataset under this location: https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neural Network architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following neural network architecture is used:\n",
        "\n",
        "<img src=\"images/cnnframe.png\" width=1200 />\n",
        "\n",
        "Though a detailed discussion of the architecture and functionality of Convnets is outside the scope of this demo, the following summary provides a brief overview ofthe design:\n",
        "- The x-ray images are resized to a 224 x 224 pixel resolution before being fed into the Convnet. Other medical imaging use cases will most likely require higher resolutions. However, for the selected dataset, high accuracy results can be achieved with this small image size.\n",
        "- During  the  data  flow  through  the Convnet, relevant  properties  for  the  classification  task (features) are extracted in a hierarchical way. The lower layers of the network detect low-level features like edges or surfaces. More complex features (for detecting pneumonia in this case) are extracted at higher layers. The three convolutional layers perform the detection of features at different abstraction levels in the network, where the images are scanned by a small moving window (kernel).\n",
        "- To reduce computational effort while focusing on the most dominant features, the image size is reduced further as the data flows through the three max pooling layers.\n",
        "- Two dropout layers are included to reduce the risk of overfitting to the training data.\n",
        "- The final layer consists of two neurons for representing the classes \"pneumonia\" and \"normal\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installs and imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download Kaggle pip package and split-folders\n",
        "%pip install kaggle --upgrade split-folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1638366710551
        }
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import json\n",
        "from azureml.core import Workspace, Dataset, Experiment\n",
        "\n",
        "workspace = Workspace.from_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Retrieve and upload data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When you use this notebook for the first time, the pneumonia dataset should be uploaded to the default AzureML datastore and registered as a managed file dataset.\n",
        "\n",
        "The commands below can be used to download the dataset using the Kaggle API (https://github.com/Kaggle/kaggle-api). Use the instructions to generate your own API key and fill them in on the code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export Kaggle configuration variables\n",
        "%env KAGGLE_USERNAME=[Kaggle user name]\n",
        "%env KAGGLE_KEY=[API token]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: KAGGLE_USERNAME=ankopp\n",
            "env: KAGGLE_KEY=7400527eb41ba5d3248625bea6f1a3bb\n"
          ]
        }
      ],
      "source": [
        "# Export Kaggle configuration variables\n",
        "%env KAGGLE_USERNAME=ankopp\n",
        "%env KAGGLE_KEY=7400527eb41ba5d3248625bea6f1a3bb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/tmp/chest_xray_tvt': No such file or directory\n",
            "Downloading chest-xray-pneumonia.zip to /tmp\n",
            "100%|██████████████████████████████████████▉| 2.29G/2.29G [00:12<00:00, 189MB/s]\n",
            "100%|███████████████████████████████████████| 2.29G/2.29G [00:12<00:00, 205MB/s]\n"
          ]
        }
      ],
      "source": [
        "# remove folders and zipfile from previous runs of the cell\n",
        "!rm /tmp/chest-xray-pneumonia.zip\n",
        "!rm -r /tmp/chest_xray\n",
        "!rm -r /tmp/chest_xray_tvt\n",
        "\n",
        "# Download the Pneumonia dataset\n",
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia -p /tmp\n",
        "\n",
        "!unzip -q /tmp/chest-xray-pneumonia.zip -d /tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying files: 5216 files [00:02, 1796.35 files/s]\n"
          ]
        }
      ],
      "source": [
        "import splitfolders\n",
        "\n",
        "download_root = '/tmp/chest_xray/train' \n",
        "train_val_test_root = '/tmp/chest_xray_tvt/'\n",
        "\n",
        "train_val_test_split = (0.8, 0.1, 0.1)\n",
        "random_seed = 33\n",
        "\n",
        "splitfolders.ratio(download_root, train_val_test_root, random_seed, ratio=train_val_test_split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val-NORMAL:  134\n",
            "val-PNEUMONIA:  387\n",
            "train-NORMAL:  1072\n",
            "train-PNEUMONIA:  3100\n",
            "test-NORMAL:  135\n",
            "test-PNEUMONIA:  388\n"
          ]
        }
      ],
      "source": [
        "# check dataset splits\n",
        "for split in os.listdir(train_val_test_root):\n",
        "    for label in ['NORMAL', 'PNEUMONIA']:\n",
        "        files = os.listdir(os.path.join(train_val_test_root, split, label))\n",
        "        print(f'{split}-{label}: ', len(files))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1638367777912
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset pneumonia registered.\n"
          ]
        }
      ],
      "source": [
        "from azureml.core import Workspace, Datastore, Dataset\n",
        "from azureml.data.datapath import DataPath\n",
        "\n",
        "# Upload data to AzureML Datastore\n",
        "ds = workspace.get_default_datastore()\n",
        "ds = Dataset.File.upload_directory(src_dir=train_val_test_root,\n",
        "            target=DataPath(ds, 'chest-xray'),\n",
        "            show_progress=False, overwrite=False)\n",
        "\n",
        "# Register file dataset with AzureML\n",
        "ds = ds.register(workspace=workspace, name=\"pneumonia\", description=\"Pneumonia train / val / test folders with 2 classes\", create_new_version=True)\n",
        "\n",
        "print(f'Dataset {ds.name} registered.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# I. Run baseline experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create/retrieve Compute Cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1638367919625
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing compute target.\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "source": [
        "from azureml.core.compute import AmlCompute, ComputeTarget\n",
        "\n",
        "cluster_name = \"gpu-cluster\"\n",
        "\n",
        "try:\n",
        "    compute_target = workspace.compute_targets[cluster_name]\n",
        "    print('Found existing compute target.')\n",
        "except KeyError:\n",
        "    print('Creating a new compute target...')\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_NC6', \n",
        "                                                           idle_seconds_before_scaledown=1800,\n",
        "                                                           min_nodes=0, \n",
        "                                                           max_nodes=4)\n",
        "\n",
        "    compute_target = ComputeTarget.create(workspace, cluster_name, compute_config)\n",
        "    \n",
        "# Can poll for a minimum number of nodes and for a specific timeout.\n",
        "# If no min_node_count is provided, it will use the scale settings for the cluster.\n",
        "compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Define ScriptRunConfig object\n",
        "\n",
        "Define the Environment that you will use to run your experiment, retrieve the dataset by name and define the ScriptRunConfig object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1632395603409
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import ScriptRunConfig, Environment\n",
        "from azureml.core.compute import ComputeTarget\n",
        "\n",
        "experiment = Experiment(workspace, 'pneumonia')\n",
        "\n",
        "pytorch_env = Environment.from_conda_specification(name = 'pytorch-1.6-gpu', file_path = './training/conda_dependencies.yml')\n",
        "\n",
        "dataset = Dataset.get_by_name(workspace, name='pneumonia', version='latest')\n",
        "\n",
        "src = ScriptRunConfig(source_directory='./training',\n",
        "                      script='train.py',\n",
        "                      arguments=['--epochs', 15, '--data-folder', dataset.as_mount()],\n",
        "                      compute_target= ComputeTarget(workspace, 'gpu-cluster'),\n",
        "                      environment=pytorch_env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Submit baseline experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1632395639804
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f875ce46af6249eaaaeaffe366c8b63b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Queued\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/pneumonia_1649589163_f3711247?wsid=/subscriptions/4eeedd72-d937-4243-86d1-c3982a84d924/resourcegroups/livecell/workspaces/livecell&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\", \"run_id\": \"pneumonia_1649589163_f3711247\", \"run_properties\": {\"run_id\": \"pneumonia_1649589163_f3711247\", \"created_utc\": \"2022-04-10T11:12:44.307352Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlctrain\", \"ContentSnapshotId\": \"7c0db779-872d-44e5-829f-16a13b13aa85\", \"azureml.git.repository_uri\": \"https://github.com/Azure/medical-imaging.git\", \"mlflow.source.git.repoURL\": \"https://github.com/Azure/medical-imaging.git\", \"azureml.git.branch\": \"main\", \"mlflow.source.git.branch\": \"main\", \"azureml.git.commit\": \"93856c68315de8efa863347a9eae8b44fc473b19\", \"mlflow.source.git.commit\": \"93856c68315de8efa863347a9eae8b44fc473b19\", \"azureml.git.dirty\": \"True\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": null, \"status\": \"Queued\", \"log_files\": {}, \"log_groups\": [], \"run_duration\": \"0:00:48\", \"run_number\": \"1649589164\", \"run_queued_details\": {\"status\": \"Queued\", \"details\": \"Job is in scheduling state\"}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"Your job is submitted in Azure cloud and we are monitoring to get logs...\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.39.0\"}, \"loading\": false}"
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from azureml.widgets import RunDetails\n",
        "\n",
        "script_run = experiment.submit(src)\n",
        "RunDetails(script_run).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# II. Hyperparameter tuning using Random Parameter Sampling\n",
        "Hyperparameter tuning, also called hyperparameter optimization, is the process of finding the configuration of hyperparameters that results in the best performance. The process is typically computationally expensive and manual.\n",
        "\n",
        "Azure Machine Learning lets you automate hyperparameter tuning and run experiments in parallel to efficiently optimize hyperparameters.\n",
        "\n",
        "Random sampling supports discrete and continuous hyperparameters. It supports early termination of low-performance runs. Some users do an initial search with random sampling and then refine the search space to improve results. In random sampling, hyperparameter values are randomly selected from the defined search space.\n",
        "\n",
        "Selected hyperparameters affect various stages of the experiment:\n",
        "\n",
        "- Data: Training and validation loader: batch size\n",
        "- CNN Architecture: Dropout\n",
        "- Choice of optimizer\n",
        "- Training loop: learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1632397981901
        }
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'src' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-62e27179a174>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mearly_termination_policy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBanditPolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslack_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay_evaluation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m hyperdrive_config = HyperDriveConfig(run_config=src,\n\u001b[0m\u001b[1;32m     14\u001b[0m                                      \u001b[0mhyperparameter_sampling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_sampling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                      \u001b[0mpolicy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_termination_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'src' is not defined"
          ]
        }
      ],
      "source": [
        "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, uniform, choice, PrimaryMetricGoal\n",
        "\n",
        "param_sampling = RandomParameterSampling( {\n",
        "        'learning_rate': choice(0.00007, 0.0007, 0.07),\n",
        "        'batch_size': choice(16, 32, 64, 128), \n",
        "        'conv_dropout' : uniform(0.0, 0.5), \n",
        "        'optimizer': choice('SGD', 'Adam', 'RMSprop')\n",
        "    }\n",
        ")\n",
        "\n",
        "early_termination_policy = BanditPolicy(slack_factor=0.15, evaluation_interval=1, delay_evaluation=5)\n",
        "\n",
        "hyperdrive_config = HyperDriveConfig(run_config=src,\n",
        "                                     hyperparameter_sampling=param_sampling, \n",
        "                                     policy=early_termination_policy,\n",
        "                                     primary_metric_name='best_val_acc',\n",
        "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "                                     max_total_runs=8,\n",
        "                                     max_concurrent_runs=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Submit hyperdrive run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1632397986782
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8314e0b6109441dc91a8110a99e0738f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/HD_866c3fbd-ae69-4450-90cc-a73534f3083c?wsid=/subscriptions/4eeedd72-d937-4243-86d1-c3982a84d924/resourcegroups/livecell/workspaces/livecell&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\", \"run_id\": \"HD_866c3fbd-ae69-4450-90cc-a73534f3083c\", \"run_properties\": {\"run_id\": \"HD_866c3fbd-ae69-4450-90cc-a73534f3083c\", \"created_utc\": \"2022-04-09T17:10:11.47985Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\": \\\"best_val_acc\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"bfd6b0c9-63bb-4c6e-b377-d59ed471d9b6\", \"user_agent\": \"python/3.8.5 (Linux-5.4.0-1073-azure-x86_64-with-glibc2.10) msrest/0.6.21 Hyperdrive.Service/1.0.0 Hyperdrive.SDK/core.1.39.0\", \"space_size\": \"infinite_space_size\", \"score\": \"0.98828125\", \"best_child_run_id\": \"HD_866c3fbd-ae69-4450-90cc-a73534f3083c_2\", \"best_metric_status\": \"Succeeded\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"4\", \"_aml_system_max_total_jobs\": \"8\", \"_aml_system_max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\": \\\"BANDIT\\\", \\\"properties\\\": {\\\"evaluation_interval\\\": 1, \\\"delay_evaluation\\\": 5, \\\"slack_factor\\\": 0.15}}\", \"_aml_system_generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"learning_rate\\\": [\\\"choice\\\", [[7e-05, 0.0007, 0.07]]], \\\"batch_size\\\": [\\\"choice\\\", [[16, 32, 64, 128]]], \\\"conv_dropout\\\": [\\\"uniform\\\", [0.0, 0.5]], \\\"optimizer\\\": [\\\"choice\\\", [[\\\"SGD\\\", \\\"Adam\\\", \\\"RMSprop\\\"]]]}}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\": \\\"best_val_acc\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://westeurope.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/4eeedd72-d937-4243-86d1-c3982a84d924/resourceGroups/livecell/providers/Microsoft.MachineLearningServices/workspaces/livecell/experiments/pneumonia\\\", \\\"SubscriptionId\\\": \\\"4eeedd72-d937-4243-86d1-c3982a84d924\\\", \\\"ResourceGroupName\\\": \\\"livecell\\\", \\\"WorkspaceName\\\": \\\"livecell\\\", \\\"ExperimentName\\\": \\\"pneumonia\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train.py\\\", \\\"arguments\\\": [\\\"--epochs\\\", 15, \\\"--data-folder\\\", \\\"DatasetConsumptionConfig:input__cdeb8e92\\\"], \\\"target\\\": \\\"gpu-cluster\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": 2592000, \\\"nodeCount\\\": 1, \\\"priority\\\": null, \\\"environment\\\": {\\\"name\\\": \\\"pytorch-1.6-gpu\\\", \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"channels\\\": [\\\"conda-forge\\\"], \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\", \\\"torch==1.6.0\\\", \\\"torchvision==0.7.0\\\", \\\"future==0.17.1\\\", \\\"pillow\\\", \\\"scikit-learn\\\", \\\"matplotlib>=3.3\\\", \\\"azureml-mlflow\\\"]}]}}, \\\"docker\\\": {\\\"enabled\\\": false, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220208.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": true}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"docker\\\": {\\\"useDocker\\\": false, \\\"sharedVolumes\\\": true, \\\"arguments\\\": [], \\\"shmSize\\\": \\\"2g\\\"}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"pytorch\\\": {\\\"communicationBackend\\\": \\\"nccl\\\", \\\"processCount\\\": null, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {\\\"input__cdeb8e92\\\": {\\\"dataLocation\\\": {\\\"dataset\\\": {\\\"id\\\": \\\"cdeb8e92-8982-4c6f-abb2-f2b9c655ca27\\\", \\\"name\\\": \\\"pneumonia\\\", \\\"version\\\": 1}, \\\"dataPath\\\": null, \\\"uri\\\": null}, \\\"createOutputDirectories\\\": false, \\\"mechanism\\\": \\\"mount\\\", \\\"environmentVariableName\\\": \\\"input__cdeb8e92\\\", \\\"pathOnCompute\\\": null, \\\"overwrite\\\": false, \\\"options\\\": null}}, \\\"datacaches\\\": [], \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": null}, \\\"kubernetescompute\\\": {\\\"instanceType\\\": null}, \\\"credentialPassthrough\\\": false, \\\"command\\\": \\\"\\\", \\\"environmentVariables\\\": {}, \\\"applicationEndpoints\\\": {}}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"bfd6b0c9-63bb-4c6e-b377-d59ed471d9b6\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"72f988bf-86f1-41af-91ab-2d7cd011db47\\\", \\\"amlClientRequestId\\\": \\\"fe5157b2-5579-40fb-bed9-e40786a47ed6\\\", \\\"amlClientSessionId\\\": \\\"967d5d59-809e-48f9-8854-f9e426b0ef3a\\\", \\\"subscriptionId\\\": \\\"4eeedd72-d937-4243-86d1-c3982a84d924\\\", \\\"estimator\\\": \\\"NoneType\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Bandit\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 8, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"_aml_system_resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"true\", \"_aml_system_cancellation_requested\": \"false\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2022-04-09T17:10:12.741729\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"53a27e128539588a3a49e6692759bbcc2feb5f1525e351c54483c4535e6d08cc\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2022-04-09T17:10:12.741729\\\"\", \"_aml_system_optimizer_state_artifact\": \"null\", \"_aml_system_outdated_optimizer_state_artifacts\": \"\\\"[]\\\"\", \"_aml_system_HD_866c3fbd-ae69-4450-90cc-a73534f3083c_0\": \"{\\\"batch_size\\\": 16, \\\"conv_dropout\\\": 0.41723940902332035, \\\"learning_rate\\\": 7e-05, \\\"optimizer\\\": \\\"Adam\\\"}\", \"_aml_system_HD_866c3fbd-ae69-4450-90cc-a73534f3083c_1\": \"{\\\"batch_size\\\": 16, \\\"conv_dropout\\\": 0.07681923231292159, \\\"learning_rate\\\": 0.0007, \\\"optimizer\\\": \\\"RMSprop\\\"}\", \"_aml_system_HD_866c3fbd-ae69-4450-90cc-a73534f3083c_2\": \"{\\\"batch_size\\\": 16, \\\"conv_dropout\\\": 0.2265523490279575, \\\"learning_rate\\\": 0.0007, \\\"optimizer\\\": \\\"RMSprop\\\"}\", \"_aml_system_HD_866c3fbd-ae69-4450-90cc-a73534f3083c_3\": \"{\\\"batch_size\\\": 128, \\\"conv_dropout\\\": 0.47199555070859567, \\\"learning_rate\\\": 0.0007, \\\"optimizer\\\": \\\"RMSprop\\\"}\", \"_aml_system_HD_866c3fbd-ae69-4450-90cc-a73534f3083c_4\": \"{\\\"batch_size\\\": 128, \\\"conv_dropout\\\": 0.0007446047399200517, \\\"learning_rate\\\": 0.07, \\\"optimizer\\\": \\\"SGD\\\"}\", \"_aml_system_HD_866c3fbd-ae69-4450-90cc-a73534f3083c_5\": \"{\\\"batch_size\\\": 64, \\\"conv_dropout\\\": 0.2495000293833708, \\\"learning_rate\\\": 0.0007, \\\"optimizer\\\": \\\"RMSprop\\\"}\", \"_aml_system_HD_866c3fbd-ae69-4450-90cc-a73534f3083c_6\": \"{\\\"batch_size\\\": 64, \\\"conv_dropout\\\": 0.00854677981020957, \\\"learning_rate\\\": 0.07, \\\"optimizer\\\": \\\"RMSprop\\\"}\", \"_aml_system_HD_866c3fbd-ae69-4450-90cc-a73534f3083c_7\": \"{\\\"batch_size\\\": 16, \\\"conv_dropout\\\": 0.41251923043844035, \\\"learning_rate\\\": 0.07, \\\"optimizer\\\": \\\"RMSprop\\\"}\", \"_aml_system_HD_866c3fbd-ae69-4450-90cc-a73534f3083c_6_cancelled\": \"true\", \"_aml_system_HD_866c3fbd-ae69-4450-90cc-a73534f3083c_7_cancelled\": \"true\", \"_aml_system_final_best_metric_update_retry_count\": \"2\"}, \"end_time_utc\": \"2022-04-09T18:03:08.792783Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://livecell0183157347.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_866c3fbd-ae69-4450-90cc-a73534f3083c/azureml-logs/hyperdrive.txt?sv=2019-07-07&sr=b&sig=WpLMz7emvf5S7JGYRSlgPgmcNuTAmThnJ6BzvnR2DRw%3D&skoid=f1f4a65d-a192-41c1-afa7-6f0f0b983b1f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-04-09T16%3A20%3A30Z&ske=2022-04-11T00%3A30%3A30Z&sks=b&skv=2019-07-07&st=2022-04-09T19%3A14%3A58Z&se=2022-04-10T03%3A24%3A58Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:52:57\", \"run_number\": \"1649524211\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}, \"hyper_parameters\": {\"learning_rate\": [\"choice\", [[7e-05, 0.0007, 0.07]]], \"batch_size\": [\"choice\", [[16, 32, 64, 128]]], \"conv_dropout\": [\"uniform\", [0.0, 0.5]], \"optimizer\": [\"choice\", [[\"SGD\", \"Adam\", \"RMSprop\"]]]}}, \"child_runs\": [{\"run_id\": \"HD_866c3fbd-ae69-4450-90cc-a73534f3083c_0\", \"run_number\": 1649524214, \"metric\": null, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2022-04-09T17:10:20.680079Z\", \"end_time\": \"2022-04-09T17:37:10.197759Z\", \"created_time\": \"2022-04-09T17:10:14.53553Z\", \"created_time_dt\": \"2022-04-09T17:10:14.53553Z\", \"duration\": \"0:26:55\", \"hyperdrive_id\": \"866c3fbd-ae69-4450-90cc-a73534f3083c\", \"arguments\": null, \"param_batch_size\": 16, \"param_conv_dropout\": 0.41723940902332035, \"param_learning_rate\": 7e-05, \"param_optimizer\": \"Adam\", \"best_metric\": 0.984375}, {\"run_id\": \"HD_866c3fbd-ae69-4450-90cc-a73534f3083c_4\", \"run_number\": 1649525864, \"metric\": null, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2022-04-09T17:37:53.166365Z\", \"end_time\": \"2022-04-09T18:00:48.038363Z\", \"created_time\": \"2022-04-09T17:37:44.604895Z\", \"created_time_dt\": \"2022-04-09T17:37:44.604895Z\", \"duration\": \"0:23:03\", \"hyperdrive_id\": \"866c3fbd-ae69-4450-90cc-a73534f3083c\", \"arguments\": null, \"param_batch_size\": 128, \"param_conv_dropout\": 0.0007446047399200517, \"param_learning_rate\": 0.07, \"param_optimizer\": \"SGD\", \"best_metric\": 0.978515625}, {\"run_id\": \"HD_866c3fbd-ae69-4450-90cc-a73534f3083c_5\", \"run_number\": 1649525894, \"metric\": null, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2022-04-09T17:38:26.316907Z\", \"end_time\": \"2022-04-09T18:02:04.421429Z\", \"created_time\": \"2022-04-09T17:38:14.784446Z\", \"created_time_dt\": \"2022-04-09T17:38:14.784446Z\", \"duration\": \"0:23:49\", \"hyperdrive_id\": \"866c3fbd-ae69-4450-90cc-a73534f3083c\", \"arguments\": null, \"param_batch_size\": 64, \"param_conv_dropout\": 0.2495000293833708, \"param_learning_rate\": 0.0007, \"param_optimizer\": \"RMSprop\", \"best_metric\": 0.982421875}, {\"run_id\": \"HD_866c3fbd-ae69-4450-90cc-a73534f3083c_7\", \"run_number\": 1649526074, \"metric\": null, \"status\": \"Canceled\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2022-04-09T17:41:21.426033Z\", \"end_time\": \"2022-04-09T17:53:30.678851Z\", \"created_time\": \"2022-04-09T17:41:14.37128Z\", \"created_time_dt\": \"2022-04-09T17:41:14.37128Z\", \"duration\": \"0:12:16\", \"hyperdrive_id\": \"866c3fbd-ae69-4450-90cc-a73534f3083c\", \"arguments\": null, \"param_batch_size\": 16, \"param_conv_dropout\": 0.41251923043844035, \"param_learning_rate\": 0.07, \"param_optimizer\": \"RMSprop\", \"best_metric\": 0.73828125}], \"children_metrics\": {\"categories\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], \"series\": {\"Train imgs\": [{\"run_id\": 1649524214, \"name\": 1649524214, \"data\": [4172.0], \"mode\": \"lines\", \"stepped\": false}, {\"run_id\": 1649526074, \"name\": 1649526074, \"data\": [4172.0], \"mode\": \"lines\", \"stepped\": false}, {\"run_id\": 1649525864, \"name\": 1649525864, \"data\": [4172.0], \"mode\": \"lines\", \"stepped\": false}, {\"run_id\": 1649525894, \"name\": 1649525894, \"data\": [4172.0], \"mode\": \"lines\", \"stepped\": false}], \"training loss\": [{\"run_id\": 1649524214, \"name\": 1649524214, \"data\": [0.1906245503144219, 0.10134355281769858, 0.07959085407292726, 0.0677818245759407, 0.0682753950615493, 0.05320758843887776, 0.04968900153143751, 0.043692896374539686, 0.03894471128956501, 0.039071113758627596, 0.035588044243483434, 0.026992021468810114, 0.024932611365119497, 0.027050523460765207, 0.0295934050915348], \"mode\": \"lines\", \"stepped\": false}, {\"run_id\": 1649526074, \"name\": 1649526074, \"data\": [134290318.97735122, 23.319081049694653, 10.923351901775353, 4.72778471958603, 1.5030387270827765, 2.4061614079534834], \"mode\": \"lines\", \"stepped\": false}, {\"run_id\": 1649525864, \"name\": 1649525864, \"data\": [0.5787760605633773, 0.5149936886327493, 0.4051000187289566, 0.2678727230426792, 0.3057513472446431, 0.1847894655778104, 0.12524037347429665, 0.09128551595163026, 0.09028914847972866, 0.07267340414818958, 0.0671737461510692, 0.05851789991784759, 0.062267799905482556, 0.0553528952232829, 0.06511629039237735], \"mode\": \"lines\", \"stepped\": false}, {\"run_id\": 1649525894, \"name\": 1649525894, \"data\": [5.0537233828126755, 0.1414133862361012, 0.1101770907326147, 0.09010078537269842, 0.07910192418532769, 0.06465201518451036, 0.05421808679174714, 0.06446298101090059, 0.04909881805484956, 0.05478809663913394, 0.039441055303023394, 0.035125440449122615, 0.044559385023889696, 0.03177341107682665, 0.02530310327617571], \"mode\": \"lines\", \"stepped\": false}], \"validation loss\": [{\"run_id\": 1649524214, \"name\": 1649524214, \"data\": [0.11928437615882412, 0.11847294114830398, 0.10746483221621522, 0.07666132223011207, 0.11130442946520053, 0.07407016441540618, 0.07410202245451439, 0.05627208619222989, 0.06408203920910775, 0.05274374843101355, 0.05623863587395472, 0.0802786765823895, 0.05397411922775852, 0.07851039430916652, 0.05667156483012747], \"mode\": \"lines\", \"stepped\": false}, {\"run_id\": 1649526074, \"name\": 1649526074, \"data\": [0.6109493959430541, 0.5657846355621279, 0.568537608675673, 0.6601224025700692, 0.5948141188630673, 0.5649864156507027], \"mode\": \"lines\", \"stepped\": false}, {\"run_id\": 1649525864, \"name\": 1649525864, \"data\": [0.600724892057979, 0.5134992617791994, 0.33350295434757754, 0.25138800821469065, 0.24546417119178113, 0.185093906012698, 0.08123417962306749, 0.20956609288012454, 0.06639839911872732, 0.10018153520097202, 0.09198344874976921, 0.0693344831924292, 0.10904496462011062, 0.07297920128205458, 0.05687400887428913], \"mode\": \"lines\", \"stepped\": false}, {\"run_id\": 1649525894, \"name\": 1649525894, \"data\": [0.17860597932636166, 0.14917217060608964, 0.1471096242915646, 0.08176009005182307, 0.09457936202267081, 0.06712736769967254, 0.06703627750191717, 0.06745569468002173, 0.05963847458705792, 0.06157583330048252, 0.06325149850744662, 0.0628048954334918, 0.055956932210190054, 0.060067624826120096, 0.05992194827138348], \"mode\": \"lines\", \"stepped\": false}], \"training accuracy\": [{\"run_id\": 1649524214, \"name\": 1649524214, \"data\": [0.9213942307692308, 0.959375, 0.9692307692307692, 0.9764423076923077, 0.9740384615384615, 0.9798076923076923, 0.9824519230769231, 0.984375, 0.9853365384615385, 0.9862980769230769, 0.9867788461538461, 0.9899038461538462, 0.990625, 0.9901442307692307, 0.989423076923077], \"mode\": \"lines\", \"stepped\": false}, {\"run_id\": 1649526074, \"name\": 1649526074, \"data\": [0.6605769230769231, 0.6987980769230769, 0.7117788461538461, 0.7016826923076923, 0.7247596153846154, 0.7242788461538462], \"mode\": \"lines\", \"stepped\": false}, {\"run_id\": 1649525864, \"name\": 1649525864, \"data\": [0.732421875, 0.7470703125, 0.75634765625, 0.89990234375, 0.89697265625, 0.931884765625, 0.950439453125, 0.96484375, 0.96484375, 0.97216796875, 0.9736328125, 0.97607421875, 0.976318359375, 0.978271484375, 0.972900390625], \"mode\": \"lines\", \"stepped\": false}, {\"run_id\": 1649525894, \"name\": 1649525894, \"data\": [0.8269230769230769, 0.9487980769230769, 0.9557692307692308, 0.9673076923076923, 0.9706730769230769, 0.975, 0.9798076923076923, 0.978125, 0.98125, 0.979326923076923, 0.9867788461538461, 0.9867788461538461, 0.9841346153846153, 0.990625, 0.9899038461538462], \"mode\": \"lines\", \"stepped\": false}], \"validation accuracy\": [{\"run_id\": 1649524214, \"name\": 1649524214, \"data\": [0.962890625, 0.96875, 0.970703125, 0.966796875, 0.974609375, 0.970703125, 0.974609375, 0.984375, 0.9765625, 0.98046875, 0.978515625, 0.966796875, 0.978515625, 0.9765625, 0.98046875], \"mode\": \"lines\", \"stepped\": false}, {\"run_id\": 1649526074, \"name\": 1649526074, \"data\": [0.73828125, 0.73828125, 0.73828125, 0.73828125, 0.73828125, 0.73828125], \"mode\": \"lines\", \"stepped\": false}, {\"run_id\": 1649525864, \"name\": 1649525864, \"data\": [0.73828125, 0.73828125, 0.9296875, 0.890625, 0.94140625, 0.91796875, 0.970703125, 0.9140625, 0.9765625, 0.95703125, 0.974609375, 0.978515625, 0.95703125, 0.978515625, 0.978515625], \"mode\": \"lines\", \"stepped\": false}, {\"run_id\": 1649525894, \"name\": 1649525894, \"data\": [0.9375, 0.94921875, 0.958984375, 0.978515625, 0.96484375, 0.974609375, 0.978515625, 0.96875, 0.98046875, 0.9765625, 0.970703125, 0.978515625, 0.978515625, 0.978515625, 0.982421875], \"mode\": \"lines\", \"stepped\": false}], \"best_val_acc\": [{\"run_id\": 1649524214, \"name\": 1649524214, \"data\": [0.962890625, 0.96875, 0.970703125, 0.970703125, 0.974609375, 0.974609375, 0.974609375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375], \"mode\": \"lines\", \"stepped\": false}, {\"run_id\": 1649526074, \"name\": 1649526074, \"data\": [0.73828125, 0.73828125, 0.73828125, 0.73828125, 0.73828125, 0.73828125], \"mode\": \"lines\", \"stepped\": false}, {\"run_id\": 1649525864, \"name\": 1649525864, \"data\": [0.73828125, 0.73828125, 0.9296875, 0.9296875, 0.94140625, 0.94140625, 0.970703125, 0.970703125, 0.9765625, 0.9765625, 0.9765625, 0.978515625, 0.978515625, 0.978515625, 0.978515625], \"mode\": \"lines\", \"stepped\": false}, {\"run_id\": 1649525894, \"name\": 1649525894, \"data\": [0.9375, 0.94921875, 0.958984375, 0.978515625, 0.978515625, 0.978515625, 0.978515625, 0.978515625, 0.98046875, 0.98046875, 0.98046875, 0.98046875, 0.98046875, 0.98046875, 0.982421875], \"mode\": \"lines\", \"stepped\": false}]}, \"metricName\": null, \"primaryMetricName\": \"best_val_acc\", \"showLegend\": true}, \"run_metrics\": [{\"name\": \"best_child_by_primary_metric\", \"run_id\": \"HD_866c3fbd-ae69-4450-90cc-a73534f3083c\", \"categories\": [0], \"series\": [{\"data\": [{\"time_elapse\": [241, 332, 423, 574, 665, 696, 788, 1272, 1272], \"metric_value\": [0.962890625, 0.96875, 0.970703125, 0.97265625, 0.974609375, 0.978515625, 0.984375, 0.98828125, 0.98828125], \"metric_name\": [\"best_val_acc\", \"best_val_acc\", \"best_val_acc\", \"best_val_acc\", \"best_val_acc\", \"best_val_acc\", \"best_val_acc\", \"best_val_acc\", \"best_val_acc\"], \"run_id\": [\"HD_866c3fbd-ae69-4450-90cc-a73534f3083c_0\", \"HD_866c3fbd-ae69-4450-90cc-a73534f3083c_0\", \"HD_866c3fbd-ae69-4450-90cc-a73534f3083c_0\", \"HD_866c3fbd-ae69-4450-90cc-a73534f3083c_2\", \"HD_866c3fbd-ae69-4450-90cc-a73534f3083c_0\", \"HD_866c3fbd-ae69-4450-90cc-a73534f3083c_1\", \"HD_866c3fbd-ae69-4450-90cc-a73534f3083c_2\", \"HD_866c3fbd-ae69-4450-90cc-a73534f3083c_2\", \"HD_866c3fbd-ae69-4450-90cc-a73534f3083c_2\"], \"final\": [false, false, false, false, false, false, false, false, true]}]}]}], \"run_logs\": \"[2022-04-09T17:10:11.824485][API][INFO]Experiment created\\r\\n[2022-04-09T17:10:12.786559][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\\r\\n[2022-04-09T17:10:13.6667947Z][SCHEDULER][INFO]Scheduling job, id='HD_866c3fbd-ae69-4450-90cc-a73534f3083c_0'\\r\\n[2022-04-09T17:10:13.7426011Z][SCHEDULER][INFO]Scheduling job, id='HD_866c3fbd-ae69-4450-90cc-a73534f3083c_1'\\r\\n[2022-04-09T17:10:13.8816002Z][SCHEDULER][INFO]Scheduling job, id='HD_866c3fbd-ae69-4450-90cc-a73534f3083c_2'\\r\\n[2022-04-09T17:10:13.9692553Z][SCHEDULER][INFO]Scheduling job, id='HD_866c3fbd-ae69-4450-90cc-a73534f3083c_3'\\r\\n[2022-04-09T17:10:13.940588][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\\r\\n[2022-04-09T17:10:14.6434282Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_866c3fbd-ae69-4450-90cc-a73534f3083c_0'\\r\\n[2022-04-09T17:10:14.7505006Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_866c3fbd-ae69-4450-90cc-a73534f3083c_2'\\r\\n[2022-04-09T17:10:14.7393010Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_866c3fbd-ae69-4450-90cc-a73534f3083c_1'\\r\\n[2022-04-09T17:10:14.8989709Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_866c3fbd-ae69-4450-90cc-a73534f3083c_3'\\r\\n[2022-04-09T17:37:43.551371][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\\r\\n[2022-04-09T17:37:43.9066631Z][SCHEDULER][INFO]Scheduling job, id='HD_866c3fbd-ae69-4450-90cc-a73534f3083c_4'\\r\\n[2022-04-09T17:37:43.876612][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\\r\\n[2022-04-09T17:37:44.7256118Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_866c3fbd-ae69-4450-90cc-a73534f3083c_4'\\r\\n[2022-04-09T17:38:13.513517][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\\r\\n[2022-04-09T17:38:13.8631894Z][SCHEDULER][INFO]Scheduling job, id='HD_866c3fbd-ae69-4450-90cc-a73534f3083c_5'\\r\\n[2022-04-09T17:38:13.816567][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\\r\\n[2022-04-09T17:38:14.8806549Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_866c3fbd-ae69-4450-90cc-a73534f3083c_5'\\r\\n[2022-04-09T17:41:13.446853][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\\r\\n[2022-04-09T17:41:13.7556747Z][SCHEDULER][INFO]Scheduling job, id='HD_866c3fbd-ae69-4450-90cc-a73534f3083c_6'\\r\\n[2022-04-09T17:41:13.8940008Z][SCHEDULER][INFO]Scheduling job, id='HD_866c3fbd-ae69-4450-90cc-a73534f3083c_7'\\r\\n[2022-04-09T17:41:13.856922][GENERATOR][INFO]Successfully sampled '2' jobs, they will soon be submitted to the execution target.\\r\\n[2022-04-09T17:41:14.3621064Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_866c3fbd-ae69-4450-90cc-a73534f3083c_6'\\r\\n[2022-04-09T17:41:14.4855699Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_866c3fbd-ae69-4450-90cc-a73534f3083c_7'\\r\\n[2022-04-09T17:41:43.429133][GENERATOR][INFO]Max number of jobs '8' reached for experiment.\\r\\n[2022-04-09T17:41:43.569084][GENERATOR][INFO]All jobs generated.\\r\\n[2022-04-09T17:51:41.552580][ENFORCER][INFO]Request cancellation of job https://westeurope.experiments.azureml.net/subscriptions/4eeedd72-d937-4243-86d1-c3982a84d924/resourceGroups/livecell/providers/Microsoft.MachineLearningServices/workspaces/livecell/experiments/**SCRUBBED**/runs/HD_866c3fbd-ae69-4450-90cc-a73534f3083c_6.\\r\\n[2022-04-09T17:51:41.731970][ENFORCER][INFO]Policy cancelled 1 jobs\\r\\n[2022-04-09T17:51:58.9095702Z][SCHEDULER][INFO]Cancelling job, id='HD_866c3fbd-ae69-4450-90cc-a73534f3083c_6'\\r\\n[2022-04-09T17:51:59.2446303Z][SCHEDULER][INFO]Updating job statuses to cancelled: [(job id = 'HD_866c3fbd-ae69-4450-90cc-a73534f3083c_6', previous status = 'RUNNING')]\\r\\n[2022-04-09T17:52:11.627582][ENFORCER][INFO]Policy cancelled 1 jobs\\r\\n[2022-04-09T17:52:11.487812][ENFORCER][INFO]Request cancellation of job https://westeurope.experiments.azureml.net/subscriptions/4eeedd72-d937-4243-86d1-c3982a84d924/resourceGroups/livecell/providers/Microsoft.MachineLearningServices/workspaces/livecell/experiments/**SCRUBBED**/runs/HD_866c3fbd-ae69-4450-90cc-a73534f3083c_6.\\r\\n[2022-04-09T17:53:11.736846][ENFORCER][INFO]Request cancellation of job https://westeurope.experiments.azureml.net/subscriptions/4eeedd72-d937-4243-86d1-c3982a84d924/resourceGroups/livecell/providers/Microsoft.MachineLearningServices/workspaces/livecell/experiments/**SCRUBBED**/runs/HD_866c3fbd-ae69-4450-90cc-a73534f3083c_7.\\r\\n[2022-04-09T17:53:12.013231][ENFORCER][INFO]Policy cancelled 1 jobs\\r\\n[2022-04-09T17:53:29.9023221Z][SCHEDULER][INFO]Cancelling job, id='HD_866c3fbd-ae69-4450-90cc-a73534f3083c_7'\\r\\n[2022-04-09T17:53:30.4950328Z][SCHEDULER][INFO]Updating job statuses to cancelled: [(job id = 'HD_866c3fbd-ae69-4450-90cc-a73534f3083c_7', previous status = 'RUNNING')]\\r\\n[2022-04-09T18:03:09.004637][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.FINISHED'.\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.39.0\"}, \"loading\": false}"
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# start the HyperDrive run\n",
        "hyperdrive_run = experiment.submit(hyperdrive_config)\n",
        "\n",
        "RunDetails(hyperdrive_run).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#  III. Define AML pipeline with HyperDriveStep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "The third part of this, is a showcase on how to use the Azure ML Pipeline capability to create a pipeline from the same training script that we have been using. In the cell below, the first step of the pipeline is created, by defining the pipeline data that will be the output of the first step.\n",
        "The Hyperdrive config that we have defined in the previous step will be re-used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1632398004456
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'hyperdrive_config' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-b20f7ff259d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m hd_step = HyperDriveStep(\n\u001b[1;32m     19\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhd_step_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mhyperdrive_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperdrive_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_mount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     outputs=[metrics_data, saved_model])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'hyperdrive_config' is not defined"
          ]
        }
      ],
      "source": [
        "from azureml.pipeline.steps import HyperDriveStep, HyperDriveStepRun, PythonScriptStep\n",
        "from azureml.pipeline.core import Pipeline, PipelineData, TrainingOutput\n",
        "\n",
        "metrics_output_name = 'metrics_output'\n",
        "metrics_data = PipelineData(name='metrics_data',\n",
        "                            datastore=workspace.get_default_datastore(),\n",
        "                            pipeline_output_name=metrics_output_name,\n",
        "                            training_output=TrainingOutput(\"Metrics\"))\n",
        "\n",
        "model_output_name = 'model_output'\n",
        "saved_model = PipelineData(name='saved_model',\n",
        "                            datastore=workspace.get_default_datastore(),\n",
        "                            pipeline_output_name=model_output_name,\n",
        "                            training_output=TrainingOutput(\"Model\",\n",
        "                                                           model_file=\"outputs/model/pneumonia.pt\"))\n",
        "\n",
        "hd_step_name='hyperdrive_step'\n",
        "hd_step = HyperDriveStep(\n",
        "    name=hd_step_name,\n",
        "    hyperdrive_config=hyperdrive_config,\n",
        "    inputs=[dataset.as_mount()],\n",
        "    outputs=[metrics_data, saved_model])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Find and register best model\n",
        "\n",
        "We add a step in our pipeline to find and register the best model, that is the output of the Hyperdrivestep."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing training/register_model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile training/register_model.py\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "from azureml.core import Workspace, Experiment, Model\n",
        "from azureml.core import Run\n",
        "from shutil import copy2\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--saved-model', type=str, dest='saved_model', help='path to saved model file')\n",
        "args = parser.parse_args()\n",
        "\n",
        "model_output_dir = './model/'\n",
        "\n",
        "os.makedirs(model_output_dir, exist_ok=True)\n",
        "copy2(args.saved_model, model_output_dir)\n",
        "\n",
        "ws = Run.get_context().experiment.workspace\n",
        "\n",
        "model = Model.register(workspace=ws, model_name='tf-dnn-mnist', model_path=model_output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1632400136821
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "conda_dep = CondaDependencies()\n",
        "conda_dep.add_pip_package(\"azureml-sdk\")\n",
        "\n",
        "rcfg = RunConfiguration(conda_dependencies=conda_dep)\n",
        "\n",
        "register_model_step = PythonScriptStep(source_directory='./training',\n",
        "                                       script_name='register_model.py',\n",
        "                                       name=\"register_model_step01\",\n",
        "                                       inputs=[saved_model],\n",
        "                                       compute_target=ComputeTarget(workspace, 'gpu-cluster'),\n",
        "                                       arguments=[\"--saved-model\", saved_model],\n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "register_model_step.run_after(hd_step)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Submit pipeline including model registration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1632400143220
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created step hyperdrive_step [bb3d6f60][c4622312-5a75-4323-b72f-7652219f234a], (This step will run and generate new outputs)\n",
            "Created step register_model_step01 [72891fc7][e63ede12-f73e-4f31-a1d1-7382d70ecf4f], (This step will run and generate new outputs)\n",
            "Submitted PipelineRun 849bb7c8-d0b4-4072-bba7-33d21323b499\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/849bb7c8-d0b4-4072-bba7-33d21323b499?wsid=/subscriptions/4eeedd72-d937-4243-86d1-c3982a84d924/resourcegroups/livecell/workspaces/livecell&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
          ]
        }
      ],
      "source": [
        "pipeline = Pipeline(workspace=workspace, steps=[hd_step, register_model_step])\n",
        "pipeline_run = experiment.submit(pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Download training metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1632402306845
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading azureml/1ac75806-bf42-4bb9-ae37-511878acc23a/metrics_data\n",
            "Downloaded azureml/1ac75806-bf42-4bb9-ae37-511878acc23a/metrics_data, 1 files out of an estimated total of 1\n"
          ]
        }
      ],
      "source": [
        "metrics_output = pipeline_run.get_pipeline_output(metrics_output_name)\n",
        "num_file_downloaded = metrics_output.download('.', show_progress=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Visualize training metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1632402314167
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HD_94cc904c-c26f-47bc-93de-27303845914e_0</th>\n",
              "      <th>HD_94cc904c-c26f-47bc-93de-27303845914e_3</th>\n",
              "      <th>HD_94cc904c-c26f-47bc-93de-27303845914e_2</th>\n",
              "      <th>HD_94cc904c-c26f-47bc-93de-27303845914e_1</th>\n",
              "      <th>HD_94cc904c-c26f-47bc-93de-27303845914e_6</th>\n",
              "      <th>HD_94cc904c-c26f-47bc-93de-27303845914e_5</th>\n",
              "      <th>HD_94cc904c-c26f-47bc-93de-27303845914e_4</th>\n",
              "      <th>HD_94cc904c-c26f-47bc-93de-27303845914e_7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>best_val_acc</th>\n",
              "      <td>[0.73828125, 0.94140625, 0.94140625, 0.9550781...</td>\n",
              "      <td>[0.947265625, 0.94921875, 0.94921875, 0.970703...</td>\n",
              "      <td>[0.291015625, 0.73828125, 0.73828125, 0.738281...</td>\n",
              "      <td>[0.935546875, 0.9453125, 0.955078125, 0.972656...</td>\n",
              "      <td>[0.923828125, 0.9375, 0.9453125, 0.955078125, ...</td>\n",
              "      <td>[0.73828125, 0.90234375, 0.923828125, 0.925781...</td>\n",
              "      <td>[0.931640625, 0.955078125, 0.978515625, 0.9785...</td>\n",
              "      <td>[0.96875, 0.97265625, 0.97265625, 0.97265625, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>validation accuracy</th>\n",
              "      <td>[0.73828125, 0.94140625, 0.9296875, 0.95507812...</td>\n",
              "      <td>[0.947265625, 0.94921875, 0.943359375, 0.97070...</td>\n",
              "      <td>[0.291015625, 0.73828125, 0.73828125, 0.738281...</td>\n",
              "      <td>[0.935546875, 0.9453125, 0.955078125, 0.972656...</td>\n",
              "      <td>[0.923828125, 0.9375, 0.9453125, 0.955078125, ...</td>\n",
              "      <td>[0.73828125, 0.90234375, 0.923828125, 0.925781...</td>\n",
              "      <td>[0.931640625, 0.955078125, 0.978515625, 0.9746...</td>\n",
              "      <td>[0.96875, 0.97265625, 0.970703125, 0.97265625,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>training accuracy</th>\n",
              "      <td>[0.7314903846153846, 0.7838942307692308, 0.872...</td>\n",
              "      <td>[0.865625, 0.9552884615384616, 0.9620192307692...</td>\n",
              "      <td>[0.71630859375, 0.71826171875, 0.744873046875,...</td>\n",
              "      <td>[0.8492788461538462, 0.9444711538461539, 0.958...</td>\n",
              "      <td>[0.80078125, 0.932861328125, 0.952880859375, 0...</td>\n",
              "      <td>[0.7418269230769231, 0.7759615384615385, 0.911...</td>\n",
              "      <td>[0.7822265625, 0.957763671875, 0.96875, 0.9760...</td>\n",
              "      <td>[0.9278846153846154, 0.9711538461538461, 0.976...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>validation loss</th>\n",
              "      <td>[0.5553653775616022, 0.2465433172895904, 0.245...</td>\n",
              "      <td>[0.14292823055655393, 0.1570459528756462, 0.17...</td>\n",
              "      <td>[0.6951569247840691, 0.5608080023767394, 0.529...</td>\n",
              "      <td>[0.16253205132804768, 0.13889057942864533, 0.1...</td>\n",
              "      <td>[0.351493095939768, 0.18049384170210064, 0.173...</td>\n",
              "      <td>[0.5273191192099778, 0.3954645850608079, 0.261...</td>\n",
              "      <td>[0.14793442123910974, 0.10387369492690074, 0.0...</td>\n",
              "      <td>[0.06922712095525123, 0.06690031610386385, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Train imgs</th>\n",
              "      <td>[4172.0]</td>\n",
              "      <td>[4172.0]</td>\n",
              "      <td>[4172.0]</td>\n",
              "      <td>[4172.0]</td>\n",
              "      <td>[4172.0]</td>\n",
              "      <td>[4172.0]</td>\n",
              "      <td>[4172.0]</td>\n",
              "      <td>[4172.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>training loss</th>\n",
              "      <td>[0.562905370560497, 0.39944255797769285, 0.340...</td>\n",
              "      <td>[0.37048336294902023, 0.12536239506871452, 0.1...</td>\n",
              "      <td>[0.5913689239370286, 0.5866566563841252, 0.540...</td>\n",
              "      <td>[5.801720656861738, 0.16121490541149078, 0.110...</td>\n",
              "      <td>[0.6851767497003249, 0.18859169192876477, 0.12...</td>\n",
              "      <td>[0.5608543389595595, 0.4458411873129847, 0.275...</td>\n",
              "      <td>[0.5561550763057954, 0.11649330224652532, 0.08...</td>\n",
              "      <td>[0.19159154064974757, 0.07936467543380087, 0.0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             HD_94cc904c-c26f-47bc-93de-27303845914e_0  \\\n",
              "best_val_acc         [0.73828125, 0.94140625, 0.94140625, 0.9550781...   \n",
              "validation accuracy  [0.73828125, 0.94140625, 0.9296875, 0.95507812...   \n",
              "training accuracy    [0.7314903846153846, 0.7838942307692308, 0.872...   \n",
              "validation loss      [0.5553653775616022, 0.2465433172895904, 0.245...   \n",
              "Train imgs                                                    [4172.0]   \n",
              "training loss        [0.562905370560497, 0.39944255797769285, 0.340...   \n",
              "\n",
              "                             HD_94cc904c-c26f-47bc-93de-27303845914e_3  \\\n",
              "best_val_acc         [0.947265625, 0.94921875, 0.94921875, 0.970703...   \n",
              "validation accuracy  [0.947265625, 0.94921875, 0.943359375, 0.97070...   \n",
              "training accuracy    [0.865625, 0.9552884615384616, 0.9620192307692...   \n",
              "validation loss      [0.14292823055655393, 0.1570459528756462, 0.17...   \n",
              "Train imgs                                                    [4172.0]   \n",
              "training loss        [0.37048336294902023, 0.12536239506871452, 0.1...   \n",
              "\n",
              "                             HD_94cc904c-c26f-47bc-93de-27303845914e_2  \\\n",
              "best_val_acc         [0.291015625, 0.73828125, 0.73828125, 0.738281...   \n",
              "validation accuracy  [0.291015625, 0.73828125, 0.73828125, 0.738281...   \n",
              "training accuracy    [0.71630859375, 0.71826171875, 0.744873046875,...   \n",
              "validation loss      [0.6951569247840691, 0.5608080023767394, 0.529...   \n",
              "Train imgs                                                    [4172.0]   \n",
              "training loss        [0.5913689239370286, 0.5866566563841252, 0.540...   \n",
              "\n",
              "                             HD_94cc904c-c26f-47bc-93de-27303845914e_1  \\\n",
              "best_val_acc         [0.935546875, 0.9453125, 0.955078125, 0.972656...   \n",
              "validation accuracy  [0.935546875, 0.9453125, 0.955078125, 0.972656...   \n",
              "training accuracy    [0.8492788461538462, 0.9444711538461539, 0.958...   \n",
              "validation loss      [0.16253205132804768, 0.13889057942864533, 0.1...   \n",
              "Train imgs                                                    [4172.0]   \n",
              "training loss        [5.801720656861738, 0.16121490541149078, 0.110...   \n",
              "\n",
              "                             HD_94cc904c-c26f-47bc-93de-27303845914e_6  \\\n",
              "best_val_acc         [0.923828125, 0.9375, 0.9453125, 0.955078125, ...   \n",
              "validation accuracy  [0.923828125, 0.9375, 0.9453125, 0.955078125, ...   \n",
              "training accuracy    [0.80078125, 0.932861328125, 0.952880859375, 0...   \n",
              "validation loss      [0.351493095939768, 0.18049384170210064, 0.173...   \n",
              "Train imgs                                                    [4172.0]   \n",
              "training loss        [0.6851767497003249, 0.18859169192876477, 0.12...   \n",
              "\n",
              "                             HD_94cc904c-c26f-47bc-93de-27303845914e_5  \\\n",
              "best_val_acc         [0.73828125, 0.90234375, 0.923828125, 0.925781...   \n",
              "validation accuracy  [0.73828125, 0.90234375, 0.923828125, 0.925781...   \n",
              "training accuracy    [0.7418269230769231, 0.7759615384615385, 0.911...   \n",
              "validation loss      [0.5273191192099778, 0.3954645850608079, 0.261...   \n",
              "Train imgs                                                    [4172.0]   \n",
              "training loss        [0.5608543389595595, 0.4458411873129847, 0.275...   \n",
              "\n",
              "                             HD_94cc904c-c26f-47bc-93de-27303845914e_4  \\\n",
              "best_val_acc         [0.931640625, 0.955078125, 0.978515625, 0.9785...   \n",
              "validation accuracy  [0.931640625, 0.955078125, 0.978515625, 0.9746...   \n",
              "training accuracy    [0.7822265625, 0.957763671875, 0.96875, 0.9760...   \n",
              "validation loss      [0.14793442123910974, 0.10387369492690074, 0.0...   \n",
              "Train imgs                                                    [4172.0]   \n",
              "training loss        [0.5561550763057954, 0.11649330224652532, 0.08...   \n",
              "\n",
              "                             HD_94cc904c-c26f-47bc-93de-27303845914e_7  \n",
              "best_val_acc         [0.96875, 0.97265625, 0.97265625, 0.97265625, ...  \n",
              "validation accuracy  [0.96875, 0.97265625, 0.970703125, 0.97265625,...  \n",
              "training accuracy    [0.9278846153846154, 0.9711538461538461, 0.976...  \n",
              "validation loss      [0.06922712095525123, 0.06690031610386385, 0.0...  \n",
              "Train imgs                                                    [4172.0]  \n",
              "training loss        [0.19159154064974757, 0.07936467543380087, 0.0...  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "with open(metrics_output._path_on_datastore) as f:  \n",
        "    metrics_output_result = f.read()\n",
        "    \n",
        "deserialized_metrics_output = json.loads(metrics_output_result)\n",
        "df = pd.DataFrame(deserialized_metrics_output)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Publish the training pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By publishing the training pipeline, an pipeline endpoint is created, that we can use to trigger the pipeline from external services."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1632402401827
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "published_pipeline1 = pipeline_run.publish_pipeline(\n",
        "     name=\"Training_pneumonia\",\n",
        "     description=\"Pipeline to train a classification model to detect pneumonia.\",\n",
        "     version=\"1.0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'4682df08-14d3-4a8b-9d61-8434ae3f8842'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "published_pipeline1.id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Create a schedule based on file change\n",
        "One advantage of defining and publishing your training script as an Azure ML Pipeline, is that a schedule can be created to trigger retraining of your model based on file changes in the source dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Pipeline(Name: MyReactiveSchedule,\n",
            "Id: 96c9feb6-8ea5-42f3-9056-562337fcf226,\n",
            "Status: Active,\n",
            "Pipeline Id: 4682df08-14d3-4a8b-9d61-8434ae3f8842,\n",
            "Pipeline Endpoint Id: None,\n",
            "Datastore: workspaceblobstore)]\n"
          ]
        }
      ],
      "source": [
        "from azureml.pipeline.core.schedule import Schedule\n",
        "\n",
        "schedule = Schedule.list(workspace) \n",
        "print(schedule)\n",
        "\n",
        "sch = Schedule.list(workspace)[0] # I want to disable the first pipeline\n",
        "    \n",
        "Schedule.disable(sch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azureml.pipeline.core import PipelineEndpoint\n",
        "\n",
        "PipelineEndpoint.list(workspace)\n",
        "\n",
        "# PipelineEndpoint.get(workspace=workspace, name=\"Training_pneumonia\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "ename": "ErrorResponseException",
          "evalue": "(BadRequest) Response status code does not indicate success: 400 (Bad Request).\nMicrosoft.RelInfra.Common.Exceptions.ErrorResponseException: PipelineEndpoint name Training_pneumonia not found in workspace a87d11b1-1984-4762-89e7-11e38d93e528",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mErrorResponseException\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-ea5e05c96aed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdatastore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_datastore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpipeline_endpoint_by_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipelineEndpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training_pneumonia\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m reactive_schedule = Schedule.create(workspace, name=\"MyReactiveSchedule\", description=\"Based on input file change.\",\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/pipeline_endpoint.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(workspace, id, name, _workflow_provider, _service_endpoint)\u001b[0m\n\u001b[1;32m    356\u001b[0m                                       service_endpoint=_service_endpoint)\n\u001b[1;32m    357\u001b[0m         \u001b[0mpipeline_endpoint_provider\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkflow_provider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline_endpoint_provider\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline_endpoint_provider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pipeline_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/_aeva_provider.py\u001b[0m in \u001b[0;36mget_pipeline_endpoint\u001b[0;34m(self, endpoint_id, name)\u001b[0m\n\u001b[1;32m   2166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2168\u001b[0;31m             \u001b[0mpipeline_endpoint_entity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_service_caller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pipeline_endpoint_by_name_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2169\u001b[0m             return self.from_pipeline_endpoint_entity(pipeline_endpoint_entity, self._workspace, self,\n\u001b[1;32m   2170\u001b[0m                                                       self._published_pipeline_provider)\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/_restclients/aeva/service_caller.py\u001b[0m in \u001b[0;36mget_pipeline_endpoint_by_name_async\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    772\u001b[0m          \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mErrorResponseException\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \"\"\"\n\u001b[0;32m--> 774\u001b[0;31m         result = self._caller.api_v10_subscriptions_by_subscription_id_resource_groups_by_resource_group_name_providers_microsoft_machine_learning_services_workspaces_by_workspace_name_pipeline_endpoint_by_name_get(\n\u001b[0m\u001b[1;32m    775\u001b[0m             \u001b[0msubscription_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_subscription_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_group_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource_group_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mworkspace_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workspace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_headers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_custom_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/_restclients/aeva/aml_pipelines_api10.py\u001b[0m in \u001b[0;36mapi_v10_subscriptions_by_subscription_id_resource_groups_by_resource_group_name_providers_microsoft_machine_learning_services_workspaces_by_workspace_name_pipeline_endpoint_by_name_get\u001b[0;34m(self, subscription_id, resource_group_name, workspace_name, name, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[1;32m   4563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4565\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mErrorResponseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4567\u001b[0m         \u001b[0mdeserialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mErrorResponseException\u001b[0m: (BadRequest) Response status code does not indicate success: 400 (Bad Request).\nMicrosoft.RelInfra.Common.Exceptions.ErrorResponseException: PipelineEndpoint name Training_pneumonia not found in workspace a87d11b1-1984-4762-89e7-11e38d93e528"
          ]
        }
      ],
      "source": [
        "from azureml.pipeline.core.schedule import Schedule\n",
        "from azureml.pipeline.core import PipelineEndpoint\n",
        "\n",
        "datastore = workspace.get_default_datastore()\n",
        "\n",
        "pipeline_endpoint_by_name = PipelineEndpoint.get(workspace=workspace, name=\"Training_pneumonia\")\n",
        "\n",
        "reactive_schedule = Schedule.create(workspace, name=\"MyReactiveSchedule\", \n",
        "                                    description=\"Based on input file change.\",\n",
        "                                    pipeline_id=pipeline_endpoint_by_name.id,\n",
        "                                    experiment_name='experiment_name',\n",
        "                                    datastore=datastore, \n",
        "                                    path_on_datastore=\"chest-xray/train/PNEUMONIA\"\n",
        "                                    data_path_parameter_name=\"input_data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "retrain_source = '/tmp/chest_xray/test'\n",
        "target_samples = './chest-xray-retrain'\n",
        "\n",
        "for label in ['NORMAL', 'PNEUMONIA']:\n",
        "    files = os.listdir(os.path.join(retrain_source, label))[:5]\n",
        "    for filename in files:\n",
        "        source = os.path.join(retrain_source, label, filename)\n",
        "        target = os.path.join(target_samples, label, 'add_'+ filename)\n",
        "        shutil.copyfile(source, target)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/tmp/chest_xray/test/NORMAL/NORMAL2-IM-0146-0001.jpeg\n",
            "./chest-xray-retrain/NORMAL/add_NORMAL2-IM-0146-0001.jpeg\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'./chest-xray-retrain/NORMAL/add_NORMAL2-IM-0146-0001.jpeg'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "name = 'NORMAL2-IM-0146-0001.jpeg'\n",
        "\n",
        "label = 'NORMAL'\n",
        "source = os.path.join('/tmp/chest_xray/test',label, name)\n",
        "target = os.path.join('./chest-xray-retrain',label,'add_'+name)\n",
        "\n",
        "print(source)\n",
        "print(target)\n",
        "\n",
        "shutil.copyfile(source, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Uploading file to chest-xray/train\n",
            "Uploading an estimated of 10 files\n",
            "Target already exists. Skipping upload for chest-xray/train/NORMAL/add_IM-0077-0001.jpeg\n",
            "Target already exists. Skipping upload for chest-xray/train/NORMAL/add_NORMAL2-IM-0146-0001.jpeg\n",
            "Target already exists. Skipping upload for chest-xray/train/NORMAL/add_NORMAL2-IM-0198-0001.jpeg\n",
            "Target already exists. Skipping upload for chest-xray/train/NORMAL/add_NORMAL2-IM-0241-0001.jpeg\n",
            "Target already exists. Skipping upload for chest-xray/train/NORMAL/add_NORMAL2-IM-0276-0001.jpeg\n",
            "Target already exists. Skipping upload for chest-xray/train/PNEUMONIA/add_person133_bacteria_637.jpeg\n",
            "Target already exists. Skipping upload for chest-xray/train/PNEUMONIA/add_person1628_virus_2821.jpeg\n",
            "Target already exists. Skipping upload for chest-xray/train/PNEUMONIA/add_person1676_virus_2892.jpeg\n",
            "Target already exists. Skipping upload for chest-xray/train/PNEUMONIA/add_person1_virus_13.jpeg\n",
            "Target already exists. Skipping upload for chest-xray/train/PNEUMONIA/add_person36_virus_81.jpeg\n",
            "Uploaded 0 files\n",
            "Creating new dataset\n"
          ]
        }
      ],
      "source": [
        "from azureml.data.datapath import DataPath\n",
        "\n",
        "ds = workspace.get_default_datastore()\n",
        "ds = Dataset.File.upload_directory(src_dir=target_samples,\n",
        "            target=DataPath(ds, 'chest-xray/train'),\n",
        "            show_progress=True, overwrite=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['test', 'train', 'val']\n",
            "/tmp/tmpx9wwwjkz\n"
          ]
        }
      ],
      "source": [
        "from azureml.core import Dataset\n",
        "import tempfile\n",
        "\n",
        "dataset = Dataset.get_by_name(workspace, name='pneumonia')\n",
        "\n",
        "mounted_path = tempfile.mkdtemp()\n",
        "\n",
        "# mount dataset onto the mounted_path of a Linux-based compute\n",
        "mount_context = dataset.mount(mounted_path)\n",
        "\n",
        "mount_context.start()\n",
        "\n",
        "import os\n",
        "print(os.listdir(mounted_path))\n",
        "print (mounted_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['add_IM-0077-0001.jpeg', 'add_NORMAL2-IM-0146-0001.jpeg', 'add_NORMAL2-IM-0198-0001.jpeg', 'add_NORMAL2-IM-0241-0001.jpeg', 'add_NORMAL2-IM-0276-0001.jpeg']\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "[Errno 30] Read-only file system: '/tmp/tmpx9wwwjkz/train/NORMAL/add_IM-0077-0001.jpeg'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-b34a669d6b1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# delete added file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madd_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/tmp/tmpx9wwwjkz/train/NORMAL/add_IM-0077-0001.jpeg'"
          ]
        }
      ],
      "source": [
        "train_root = os.path.join(mounted_path, 'train')\n",
        "\n",
        "for label in ['NORMAL', 'PNEUMONIA']:\n",
        "    add_files = [file for file in os.listdir(os.path.join(train_root, label)) if file.startswith('add_')]\n",
        "    print(add_files)\n",
        "    # delete added file\n",
        "    for file in add_files:\n",
        "        os.remove(os.path.join(train_root, label, file))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.6 - AzureML",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
